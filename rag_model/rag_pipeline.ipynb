{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d88c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Koustav Chatterjee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Koustav Chatterjee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google import genai\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429996f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environmental variables\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4698ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold to address notes not being in RAG\n",
    "NOT_IN_RAG_THRESHOLD = 0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a22476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545e0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8108383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity search\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    dot_prod = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0\n",
    "\n",
    "    return dot_prod / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d869401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, embeddings, k=3):\n",
    "    query_emb = model.encode(query)\n",
    "\n",
    "    scores = []\n",
    "    for emb in embeddings:\n",
    "        score = cosine_similarity(query_emb, np.array(emb[\"embedding\"]))\n",
    "        scores.append((score, emb))\n",
    "\n",
    "    scores.sort(reverse=True, key=lambda x: x[0])\n",
    "    return scores[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff88417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate a postfix expression, you can follow these steps:\n",
      "\n",
      "1.  **Scan from Left to Right**: Look at the expression from the beginning to the end.\n",
      "2.  **Handle Operands**: If you see a number or a variable (an operand), just keep going.\n",
      "3.  **Handle Operators**: When you find an operator (like +, -, *, /), apply that operation to the two operands that came just before it.\n",
      "4.  **Replace and Continue**: Replace those two operands and the operator with the result of your calculation. Now you have one new value, and you continue scanning the rest of the expression with this new value in place.\n",
      "\n",
      "This process is often done easily using a stack.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "with open(\"json/embeddings.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    embeddings = json.load(f)\n",
    "\n",
    "user_query = \"How to calculate postfix expression?\"\n",
    "\n",
    "retrieved = retrieve(user_query, embeddings)\n",
    "max_score = retrieved[0][0]\n",
    "\n",
    "if max_score < NOT_IN_RAG_THRESHOLD:\n",
    "    context = None\n",
    "else:\n",
    "    context = \"\\n\\n\".join(c[\"content\"] for _, c in retrieved)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert study helper.\n",
    "Give answer to the user query based on the provided context.\n",
    "Use the context only if it exists.\n",
    "If no context is available, say clearly that user has not studied that topic yet.\n",
    "\n",
    "Think step-by-step carefully and reason internally before answering.\n",
    "Answer in simple english to the user.\n",
    "\n",
    "User Query:\n",
    "{user_query}\n",
    "\n",
    "{\n",
    "    f'''Context:\n",
    "{context}'''\n",
    "    if context\n",
    "    else \"\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
