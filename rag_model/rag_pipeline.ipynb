{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d88c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Koustav Chatterjee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Koustav Chatterjee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google import genai\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429996f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environmental variables\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a22476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545e0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8108383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity search\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    dot_prod = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0\n",
    "\n",
    "    return dot_prod / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d869401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, embeddings, k=3):\n",
    "    query_emb = model.encode(query)\n",
    "\n",
    "    scores = []\n",
    "    for emb in embeddings:\n",
    "        score = cosine_similarity(query_emb, np.array(emb[\"embedding\"]))\n",
    "\n",
    "        scores.append((score, emb))\n",
    "\n",
    "    scores.sort(reverse=True, key=lambda x: x[0])\n",
    "    return [ing for _, ing in scores[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff88417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A stack is an Abstract Data Type (ADT) that behaves like a real-world stack, such as a deck of cards or a pile of plates. It allows operations (like placing or removing items) to occur only at one end, which is always referred to as the \"top\" of the stack.\n",
      "\n",
      "This characteristic makes it a **LIFO** (Last-In-First-Out) data structure, meaning the last element added to the stack is the first one to be removed.\n",
      "\n",
      "Key operations include:\n",
      "*   **push()**: Adding an element to the top of the stack.\n",
      "*   **pop()**: Removing an element from the top of the stack.\n",
      "\n",
      "There are also other useful functions like:\n",
      "*   **peek()**: To look at the top element without removing it.\n",
      "*   **isFull()**: To check if the stack is full.\n",
      "*   **isEmpty()**: To check if the stack is empty.\n",
      "\n",
      "A pointer, called 'top', always keeps track of the last element pushed onto the stack. Stacks can be of fixed size or dynamically resize, and they can be implemented using arrays for a fixed-size version.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "with open(\"embeddings.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    embeddings = json.load(f)\n",
    "\n",
    "user_query = \"What is a stack?\"\n",
    "\n",
    "retrieved = retrieve(user_query, embeddings, k=3)\n",
    "\n",
    "context = \"\\n\\n\".join(c[\"content\"] for c in retrieved)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert study helper and remember everything the user has studied.\n",
    "Give answer to the user query based on the provided context only.\n",
    "\n",
    "User Query:\n",
    "{user_query}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer in simple english to the user.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
